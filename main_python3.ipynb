{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-12 01:02:31--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.139.181\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.139.181|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "import numpy as np\n",
    "import re # 텍스트 전처리\n",
    "import csv, random\n",
    "from gensim.models import KeyedVectors # 미리 훈련된 단어 벡터 읽기\n",
    "from moviepy.editor import *\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"GoogleNews-vectors-negative300.bin.gz\"\n",
    "w2v_mod = KeyedVectors.load_word2vec_format(FILENAME, binary=True, limit=300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_txt, source=\"ko\", target=\"en\"):\n",
    "    cloud_url = \"https://naveropenapi.apigw.ntruss.com/nmt/v1/translation\"\n",
    "    r = requests.post(cloud_url,\n",
    "                      headers={\"X-NCP-APIGW-API-KEY-ID\":\"ikoxgv3qyf\",\n",
    "                               \"X-NCP-APIGW-API-KEY\":\"SfjIg59wfjz43peNO3yLy0XO152qJ7EU4uEGZTAX\"},\n",
    "                      data={\"source\": source, \"target\": target, \"text\": input_txt})\n",
    "    info = json.loads(r.text)\n",
    "    return info[\"message\"][\"result\"][\"translatedText\"]\n",
    "\n",
    "def getKeywords(sentence):\n",
    "    # input = 'hello I ate chicken'\n",
    "    # output = ['ate', 'chicken']\n",
    "    speechs = ['JJ','JJR','JJS','RB','RBR','UH','VB','VBD','VBG','VBN','VBP','VBZ','NN','NNS','NNP','NNPS']\n",
    "    txt = translate(sentence)\n",
    "    \n",
    "    sentences = nltk.sent_tokenize(txt)\n",
    "    data, datas = [], []\n",
    "    \n",
    "    for sent in sentences:\n",
    "        data = data + nltk.pos_tag(nltk.word_tokenize(sent))\n",
    "    # print(data)\n",
    "    for word in data:\n",
    "        if speechs.count(word[1])!= 0:\n",
    "            # print(word)\n",
    "            datas.append(word[0])\n",
    "    # print(datas)\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO get keywords\n",
    "# 변수 설명\n",
    "# idx: word에 해당하는 index에 대해서  motion 번호를 입력해둠\n",
    "# word: tag 단어들\n",
    "# path: 각 모션의 path, 추후 api 사용하게 될 시에 필요함\n",
    "\n",
    "# keywords = ['play', 'cellphone', 'game', 'teammates', 'knowing']\n",
    "def most_relevant_tag(keywords):\n",
    "    f = io.open('data.csv', 'r', encoding='utf-8')\n",
    "    rdr = csv.reader(f)\n",
    "\n",
    "    words = []\n",
    "    path = []\n",
    "    idx = []\n",
    "\n",
    "    for i, line in enumerate(rdr):\n",
    "        n = 0\n",
    "        tmp = line[2:]\n",
    "        for w in tmp:\n",
    "            try:\n",
    "                w2v_mod[w]\n",
    "            except KeyError:\n",
    "                pass\n",
    "            else:\n",
    "                if w not in words and w != '':\n",
    "                    words.append(w)\n",
    "                    idx.append([i])\n",
    "                    n = n + 1\n",
    "                elif w != '':\n",
    "                    idx[words.index(w)].append(i)\n",
    "        path.append(line[1])\n",
    "\n",
    "    f.close()\n",
    "\n",
    "\n",
    "    s_temp = []\n",
    "\n",
    "    for k, word in enumerate(words):\n",
    "        s_temp.append([])\n",
    "        for j, key in enumerate(keywords):\n",
    "            s_temp[k].append(w2v_mod.similarity(word, key))\n",
    "\n",
    "    S = np.sum(s_temp, axis=1)/len(keywords) # 모든 keyword에 대해서 유사도를 합한 행렬\n",
    "\n",
    "    score = [0] * (i+1) # 각 영상들의 tag 점수를 더해서 tag 갯수로 나눈것\n",
    "    num = [0] * (i+1) # 영상들의 tag 갯수\n",
    "\n",
    "    for key, p in enumerate(idx):\n",
    "        for q in p:\n",
    "            score[q] = score[q] + S[key]\n",
    "            num[q] = num[q] + 1\n",
    "\n",
    "    score_norm = [0]*len(score) # 영상들의 tag의 평균 점수\n",
    "\n",
    "    for r in range(len(score)):\n",
    "        score_norm[r] = score[r]/num[r]\n",
    "\n",
    "    m = np.argmax(score_norm) # max index (can know which tag is the max)\n",
    "\n",
    "    # 해당 index에 해당하는 모션이 많을 경우 랜덤으로 하나 뽑아줌\n",
    "    # t = random.sample(idx[m],1)\n",
    "\n",
    "    # 해당 모션에 대해서 path를 받아옴\n",
    "    # p = path[t[0]]\n",
    "    p = path[m]\n",
    "    return str(m)  # return index\n",
    "    '''\n",
    "    f = io.open('data.csv', mode='r', encoding='utf-8')\n",
    "    rdr = csv.reader(f)\n",
    "\n",
    "    words = []\n",
    "    path = []\n",
    "    idx = []\n",
    "\n",
    "    for i, line in enumerate(rdr):\n",
    "        n = 0\n",
    "        tmp = line[2:]\n",
    "        for w in tmp:\n",
    "            try:\n",
    "                w2v_mod[w]\n",
    "            except KeyError:\n",
    "                pass\n",
    "            else:\n",
    "                if w not in words and w != '':\n",
    "                    words.append(w)\n",
    "                    idx.append([i])\n",
    "                    n = n + 1\n",
    "                elif w != '':\n",
    "                    idx[words.index(w)].append(i)\n",
    "        path.append(line[1])\n",
    "\n",
    "    f.close\n",
    "\n",
    "    W = []\n",
    "\n",
    "    for word in words:\n",
    "        try:\n",
    "            W.append(w2v_mod[word])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    W_n = np.array(W) # tag에 있는 모든 단어들에 대해서 300차원의 vector를 모아둔 n * 300 차원의 행렬\n",
    "\n",
    "    K = []\n",
    "\n",
    "    for key in keywords:\n",
    "        K.append(w2v_mod[key])\n",
    "\n",
    "    K_n = np.array(K) # 문장에서 얻어낸 keyword의 vector를 모아둔 k* 300 차원의 행렬\n",
    "    K_n = K_n.transpose() # W와 곱하기 위해서 transpose 해준 300 * k 행렬\n",
    "\n",
    "    s_temp = np.matmul(W_n , K_n) # keyword에 대해 각각 유사도 점수를 나타내는 행렬\n",
    "\n",
    "    S = np.sum(s_temp, axis=1)/len(keywords) # 모든 keyword에 대해서 유사도를 합한 행렬\n",
    "\n",
    "    score = [0] * (i+1) # 각 영상들의 tag 점수를 더해서 tag 갯수로 나눈것\n",
    "    num = [0] * (i+1) # 영상들의 tag 갯수\n",
    "\n",
    "    for key, p in enumerate(idx):\n",
    "        for q in p:\n",
    "            score[q] = score[q] + S[key]\n",
    "            num[q] = num[q] + 1\n",
    "\n",
    "    score_norm = [0]*len(score) # 영상들의 tag의 평균 점수\n",
    "\n",
    "    for r in range(len(score)):\n",
    "        score_norm[r] = score[r]/num[r]\n",
    "\n",
    "    m = np.argmax(score_norm) # max index (can know which tag is the max)\n",
    "\n",
    "    # 해당 index에 해당하는 모션이 많을 경우 랜덤으로 하나 뽑아줌\n",
    "    # t = random.sample(idx[m],1)\n",
    "\n",
    "    # 해당 모션에 대해서 path를 받아옴\n",
    "    # p = path[t[0]]\n",
    "    p = path[m]\n",
    "    return str(m)  # return index\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produceVideo(clip_list): \n",
    "    # input format = ['ANI_74', 'ANI_67', ....]\n",
    "    # assume that clips are saved locally as ANI_74.MOV, ANI_67.MOV, ...\n",
    "    if not clip_list:\n",
    "        print(\"NO CLIPS\")\n",
    "        return None\n",
    "    for i in range(len(clip_list)):\n",
    "        clip_list[i] = clip_list[i] + \".mp4\"\n",
    "    # print(\"clip_list = %s\" % clip_list)\n",
    "    clip = clip_list[0]\n",
    "    for i in range(len(clip_list)):\n",
    "        if i < len(clip_list)-1:\n",
    "            clip = concatenateVideo(clip, clip_list[i+1])\n",
    "    return clip\n",
    "                \n",
    "def concatenateVideo(path_to_clip1='clip1.mp4', path_to_clip2='clip2.mp4', path_to_output='render.mp4'):\n",
    "    # clip1 + clip2 => output\n",
    "    clip1 = VideoFileClip(path_to_clip1)\n",
    "    clip2 = VideoFileClip(path_to_clip2)\n",
    "    finalrender = concatenate_videoclips([clip1, clip2])\n",
    "    finalrender.write_videofile(path_to_output, codec='libx264')\n",
    "    return path_to_output\n",
    "\n",
    "def showVideo(path_to_video='render.mp4'):\n",
    "    video = io.open(path_to_video, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    HTML(data='''<video alt=\"test\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "    </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence = Today was a very nice day.\n",
      "keywords = [u'Today', u'was', u'very', u'nice', u'day']\n",
      "sentence = I won the Dance Festival Award.\n",
      "keywords = [u'won', u'Dance', u'Festival', u'Award']\n",
      "sentence = Everyone clapped their hands.\n",
      "keywords = [u'Everyone', u'clapped', u'hands']\n",
      "sentence = It was a proud dance.\n",
      "keywords = [u'was', u'proud', u'dance']\n",
      "sentence = Bye\n",
      "keywords = [u'Bye']\n",
      "clips index = ['38', '72', '69', '72', '39']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   1%|          | 6/889 [00:00<00:15, 58.45it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video render.mp4.\n",
      "Moviepy - Writing video render.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready render.mp4\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    clips = []\n",
    "    f = open(\"diary.txt\", 'r')\n",
    "    for line in f:\n",
    "        sentence = line.split('\\n')[0]\n",
    "        print(\"sentence = %s\" % sentence)\n",
    "        keywords = getKeywords(sentence)  # sentence -> keywords\n",
    "        print(\"keywords = %s\" % keywords)   \n",
    "        clipIndex = most_relevant_tag(keywords)  # keywords -> video!\n",
    "        clips.append(clipIndex)\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "    print(\"clips index = %s\" % clips)\n",
    "    clips = ['clip1', 'clip2']  # clip 되면 \n",
    "    path_to_resultVideo = produceVideo(clips)\n",
    "    video = io.open(path_to_resultVideo, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    HTML(data='''<video alt=\"test\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "    </video>'''.format(encoded.decode('ascii')))\n",
    "\n",
    "\n",
    "    # 행동하면서 낭독까지??? videobooth \n",
    "    # 비디오부스를 뭐로 분류할지? 소팅 --> 서칭이 안되니까.\n",
    "    # 거기서도 라벨링은 수동으로 : 감정은 아직. 기본적 행동만. 현재는. 대분류 - 소분류 고민중.\n",
    "    # ㅇㄹㅇㄹㅇㄹㅇㄹㅇㄹ: 어떻게 한꺼번에 다운???\n",
    "    # 디자인은 이렇게 하겠습니다.\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
