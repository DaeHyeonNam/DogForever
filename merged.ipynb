# HTTP Post
# https://apidocs.ncloud.com/ko/ai-naver/papago_nmt/translation/

import requests
import json
import nltk
from nltk.corpus import state_union
from nltk.tokenize import PunktSentenceTokenizer

speechs = ['JJ','JJR','JJS','RB','RBR','UH','VB','VBD','VBG','VBN','VBP','VBZ']
sen_len = 1


def translate(input_txt, source="ko", target="en"):
    cloud_url = "https://naveropenapi.apigw.ntruss.com/nmt/v1/translation"
    r = requests.post(cloud_url,
                      headers={"X-NCP-APIGW-API-KEY-ID":"ikoxgv3qyf",
                               "X-NCP-APIGW-API-KEY":"SfjIg59wfjz43peNO3yLy0XO152qJ7EU4uEGZTAX"},
                      data={"source": source, "target": target, "text": input_txt})    
    info = json.loads(r.text)
    return info["message"]["result"]["translatedText"]

f = open("diary.txt", 'r')
lines = []
while True:
    line = f.readline()
    lines.append(line.split('\n')[0])
    if not line: break
        
for i in range (0, len(lines)-1):
    print(lines[i])
    txt = translate(lines[i])
    print(txt)
#     document = 'Today the Netherlands celebrates King\'s Day. To honor this tradition, the Dutch embassy in San Francisco invited me to'
    sentences = nltk.sent_tokenize(txt)   
    data, datas = [], []

    for sent in sentences:
        data = data + nltk.pos_tag(nltk.word_tokenize(sent))
    print(data)
    for word in data: 
        if speechs.count(word[1])!= 0: 
            print(word)
            datas.append(word[0])
    print(datas)
    
f.close()
